# 1.- Warming up with two support tickets:

Ticket #1

Hi folks,
I wanted to add interactivity to my map, but for some reason I can't make my popups work. What am I doing wrong? Please find my code here. Thanks!
Please find my code [here](https://gist.github.com/pablomoniz/51568ba2dbfdba51ecfe35904e361a07#file-index-html), and a live version [here](https://bl.ocks.org/pablomoniz/raw/51568ba2dbfdba51ecfe35904e361a07). Thanks!

Ticket #2

Hello Support,
I'm going through your materials, I've seen this query somewhere, and I'd need some help from your side on understanding what it does, can you give me a hand?

```sql
      SELECT e.name,
             count(*) AS counts,
             sum(p.population) as population
        FROM european_countries e
        JOIN populated_places p
          ON ST_Intersects(p.the_geom, e.the_geom)
    GROUP BY e.name
``` 


# 2.- Python Support Engineer Test - Sample creation

A customer would like to host and provision 10 row data samples to their clients and, since some source data would be geospatial, has decided to use CARTO for this purpose and would like a CARTO Support Team to help with that.

**Goal:**

Develop an ETL routine that reads a CSV or geospatial dataset, limits the results to 10 rows and then uploads it to a CARTO account.

The routine can be created in a .py script or Notebook format such as Jupyter Notebook. 

Code efficiency, style and explanation will be evaluated.

**Materials:**

[Sample dataset](https://data.cityofnewyork.us/Education/NYC-School-District-Boundaries/p5vh-vm7p)

Steps for creating a free CARTO account [here](https://drive.google.com/file/d/13NAtbPdFoLPNqRtiMcDRpBRt7htwCJfb/view)

**Delivearable**

You can share the notebook, or the .py file(s) and all the relevant information :)

**Bonus Track [OPTIONAL]**

Create a routine that reads and uploads a CSV dataset into CARTO in chunks of approximately 100 MB.

For example, if the CSV file size is 500 MB, it should read 100 MB and transfer them into CARTO, then the next 100 MB and so on until the complete file has been pushed into the corresponding CARTO dataset.

**Resources**

You can use any documentation available. 

TIP: Within our [Developer Center CARTOframes page](https://carto.com/developers/cartoframes/) you can find some potentially useful resources: 

In addition, here you can find specific useful links:

https://carto.com/developers/cartoframes/guides/Authentication/

https://carto.com/developers/cartoframes/guides/Data-Management/

https://carto.com/developers/cartoframes/examples/#example-upload-to-carto ðŸ‘€ 

https://carto.com/developers/cartoframes/reference/

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html 




# 3.- Docker Support Engineer Test
We need to test a new environment and we'd like to do it as aseptic as possible. To do so, we are going to use **Docker Compose**.

**Side notes**
- We can use either a local or a virtual machine
- All procedures (even docker installation) should be done via command line interface (not desktop tool)

**Delivearable**
Please, share with us:
- list of commands you have used during the complete process -a brief explanation of the commands will get you extra points!
- screenshots are welcome!
- yml file for postgres configuration -original parameters are welcome!

**Goal**

**1.- Install dependencies (depending on your environment you'll need to install more libraries):**
- Docker
- Docker Compose version 1.25.3

**2.- Check Docker & Docker Compose version.**

**3.- Start a `postgres 12` instance using `docker-compose`**

**4.- Check docker volume location**

**5.- Stop the instance**

**6.- Destroy any trace of Docker instances ðŸ”¥**

---
**Bonus Track (Optional)**

Enter postgres container 
- check postgres port
- check postgresql version